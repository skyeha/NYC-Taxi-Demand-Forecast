{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/26 01:04:31 WARN Utils: Your hostname, DESKTOP-H6V94HM resolves to a loopback address: 127.0.1.1; using 192.168.0.100 instead (on interface eth0)\n",
      "24/08/26 01:04:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/26 01:04:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1 Raw Data Collection\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config('spark.driver.memory', '4g')\n",
    "    .config('spark.executor.memory', '2g')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if raw folder exist, if not create one\n",
    "output_dir = '../data/raw'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLC Trips Records Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trips_data_retrieval(data_range, service_types, dir):\n",
    "    \"\"\"\n",
    "        This function retrieves data from a specified year, month, and service type. The data is then stored in the designated directory\n",
    "            `data_range`: dictionary - {'2023': 3, '2024': range(1,6)}\n",
    "            `service_types`: list - ['yellow', 'green', 'fhv', 'fhvhv']\n",
    "            `dir`: string\n",
    "    \"\"\"\n",
    "\n",
    "    URL_TEMPLATE = {\n",
    "        'yellow': \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_\",\n",
    "        'green': \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_\",\n",
    "        'fhv': \"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_\",\n",
    "        'fhvhv': \"https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_\"\n",
    "    }\n",
    "\n",
    "    for service in service_types:\n",
    "        if service not in URL_TEMPLATE.keys():\n",
    "            print(f\"The following service(s) does not exist: {service}\")\n",
    "            next\n",
    "        if not os.path.exists(f\"{dir}/{service.lower()}\"):\n",
    "            os.makedirs(f\"{dir}/{service.lower()}\")\n",
    "        \n",
    "        for YEAR, MONTHS in data_range.items():\n",
    "            for month in MONTHS:\n",
    "                month = str(month).zfill(2)\n",
    "\n",
    "                if os.path.exists(f\"{dir}/{service.lower()}/{YEAR}-{month}.parquet\"):\n",
    "                    next\n",
    "\n",
    "                # Generate URL to retrieve data\n",
    "                url = f\"{URL_TEMPLATE[service.lower()]}{YEAR}-{month}.parquet\"\n",
    "\n",
    "                # Setting up directory to store data\n",
    "                output_dir = f\"{dir}/{service.lower()}/{YEAR}-{month}.parquet\"\n",
    "\n",
    "                # Download data\n",
    "                urlretrieve(url, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining range of data that we want to get\n",
    "data_range = {'2023': range(3,13), '2024': range(1,6)}\n",
    "\n",
    "# Retrieve data\n",
    "trips_data_retrieval(data_range, [\"yellow\", \"green\"], output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive taxi zone lookup data\n",
    "output_dir = '../data/raw'\n",
    "\n",
    "urlretrieve(\"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\",\n",
    "            \"../data/raw/taxi_zone_lookup.csv\")\n",
    "\n",
    "import zipfile\n",
    "\n",
    "# Retrieve the shape files of the zones\n",
    "if not os.path.exists(\"../data/raw/taxi_zone_shape\"):\n",
    "    os.mkdir(\"../data/raw/taxi_zone_shape\")\n",
    "    \n",
    "urlretrieve(\"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip\",\n",
    "            \"../data/raw/taxi_zones.zip\")\n",
    "\n",
    "with zipfile.ZipFile(\"../data/raw/taxi_zones.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"../data/raw/taxi_zone_shape\")\n",
    "\n",
    "# Remove the zip file\n",
    "os.remove(\"../data/raw/taxi_zones.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving data's weather from National Centers for Environmental Information's Integrated Surfaced Dataset, ranging from March 2023 to May 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir =\"../data/raw/weather\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir) \n",
    "\n",
    "WEATHER_URL = {'2023': 'https://www.ncei.noaa.gov/data/global-hourly/access/2023/72503014732.csv', \n",
    "               '2024': 'https://www.ncei.noaa.gov/data/global-hourly/access/2024/72503014732.csv'}\n",
    "\n",
    "for period, url in WEATHER_URL.items():\n",
    "    destination = f\"{output_dir}/{period}-weather.csv\"\n",
    "\n",
    "    urlretrieve(url, destination)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the files from `.csv` to `.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/26 01:13:27 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(\"../data/raw/weather\"):\n",
    "    df = spark.read.csv(\"../data/raw/weather/\" + file, header=True, inferSchema=False)\n",
    "\n",
    "    if not os.path.exists(f\"../data/raw/{file[0:12]}\"):\n",
    "        df.write.parquet(f\"../data/raw/{file[0:12]}\")\n",
    "\n",
    "    os.remove(\"../data/raw/weather/\" + file)\n",
    "    \n",
    "os.removedirs(\"../data/raw/weather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Socio-Economic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply downloaded the data on unemployment rate of New York City on at [U.S. BUREAU OF LABOR STATISTICS](https://data.bls.gov/dataViewer/view/timeseries/LAUBS360000000000003) on the website as there is no retrievable URL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
